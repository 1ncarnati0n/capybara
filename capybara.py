import os
import gc
from typing import List, Union
import time
from datetime import timedelta
import logging
import warnings
import platform
import shutil
import zipfile

import chardet
import ebooklib
from ebooklib import epub
from langdetect import detect
import nltk
from vllm import LLM, SamplingParams
from bs4 import BeautifulSoup
import gradio as gr
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline
import torch

logging.getLogger().disabled = True
logging.raiseExceptions = False
warnings.filterwarnings('ignore')
nltk.download('punkt', quiet=True)

PathType = Union[str, os.PathLike]

class Capybara:
    def __init__(self, max_len: int = 2048):
        self.max_len = max_len
        self.selected_files = []

        self.upload_msg = None
        self.origin_lang_str = None
        self.target_lang_str = None
        self.origin_lang = None
        self.target_lang = None

        self.upload_files = None

        # ëª¨ë¸ íƒ€ì… ì„ íƒ (llm ë˜ëŠ” s2s)
        self.model_type = "llm"  # ê¸°ë³¸ê°’: LLM

        # vLLM ëª¨ë¸ ì„¤ì •
        self.selected_model = "davidkim205/iris-7b"
        self.llm = None
        self.sampling_params = None
        self.loaded_model_name = None  # í˜„ì¬ ë¡œë“œëœ vLLM ëª¨ë¸ëª…

        # Seq2Seq ëª¨ë¸ ì„¤ì •
        self.s2s_model = None
        self.s2s_tokenizer = None
        self.src_lang = None
        self.tgt_lang = None

        self.output_folder = 'outputs'
        self.temp_folder_1 = 'temp_1'
        self.temp_folder_2 = 'temp_2'
        self.css = """
            .radio-group .wrap {
                display: float !important;
                grid-template-columns: 1fr 1fr;
            }
            .log-box {
                max-height: 300px;
                overflow-y: auto;
                font-family: monospace;
                font-size: 12px;
            }
            """
        self.start = None
        self.platform = platform.system()

        # ë²ˆì—­ ë¡œê·¸ íˆìŠ¤í† ë¦¬
        self.translation_logs = []

    def remove_folder(self, temp_folder: PathType):
        if os.path.exists(temp_folder):
            shutil.rmtree(temp_folder)

    def reset_translation_state(self):
        """ë²ˆì—­ ì™„ë£Œ í›„ ìƒíƒœ ì´ˆê¸°í™” (ëª¨ë¸ì€ ìœ ì§€)"""
        self.selected_files = []
        self.origin_lang_str = None
        self.target_lang_str = None
        self.origin_lang = None
        self.target_lang = None

        # Seq2Seq ëª¨ë¸ì˜ ì–¸ì–´ ì„¤ì •ë§Œ ì´ˆê¸°í™” (ëª¨ë¸ ìì²´ëŠ” ìœ ì§€)
        self.src_lang = None
        self.tgt_lang = None

        # ì„ì‹œ í´ë” ì •ë¦¬
        self.remove_folder(self.temp_folder_1)
        self.remove_folder(self.temp_folder_2)

    def add_translation_log(self, model_name: str, duration: str, file_count: int, lang_direction: str):
        """ë²ˆì—­ ë¡œê·¸ ì¶”ê°€"""
        from datetime import datetime

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] {model_name} | {lang_direction} | {file_count}ê°œ íŒŒì¼ | {duration}"

        self.translation_logs.append(log_entry)

        # ìµœëŒ€ 50ê°œê¹Œì§€ë§Œ ìœ ì§€
        if len(self.translation_logs) > 50:
            self.translation_logs = self.translation_logs[-50:]

        return "\n".join(self.translation_logs)

    def get_translation_logs(self):
        """í˜„ì¬ ë²ˆì—­ ë¡œê·¸ ë°˜í™˜"""
        if not self.translation_logs:
            return "ì•„ì§ ë²ˆì—­ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        return "\n".join(self.translation_logs)

    def main(self):
        self.remove_folder(self.temp_folder_1)
        self.remove_folder(self.temp_folder_2)

        with gr.Blocks(
            css=self.css,
            title='Capybara',
            theme=gr.themes.Default(primary_hue="blue", secondary_hue="cyan")
        ) as app:
            gr.HTML("<div align='center'><h1 style='margin-top:10px;'>AI í•œì˜/ì˜í•œ ë²ˆì—­ê¸° <span style='color:blue'>ì¹´í”¼ë°”ë¼</span></h1><p style='color:gray;'>LLM + Seq2Seq ë“€ì–¼ ëª¨ë¸ ì§€ì›</p></div>")

            with gr.Row():
                with gr.Column(scale=1, min_width=300):
                    with gr.Tab('ìˆœì„œ 1'):
                        gr.Markdown("<h3>1. ë²ˆì—­í•  íŒŒì¼ë“¤ ì„ íƒ</h3>")
                        input_window = gr.File(
                            file_count="multiple",
                            file_types=[".txt", ".epub", ".srt"],
                            label='íŒŒì¼ë“¤'
                        )
                        lang_msg = gr.HTML(self.upload_msg)
                        input_window.change(
                            fn=self.change_upload,
                            inputs=input_window,
                            outputs=lang_msg,
                            preprocess=False
                        )

                with gr.Column(scale=2):
                    with gr.Tab('ìˆœì„œ 2'):
                        gr.Markdown("<h3>2. ë²ˆì—­ ëª¨ë¸ ì„ íƒ</h3>")
                        model_selector = gr.Radio(
                            choices=[
                                ("LLM (iris-7b) - ë¹ ë¥´ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­ âš¡", "llm"),
                                ("Seq2Seq (NLLB) - ì•ˆì •ì ì´ê³  ì •í™•í•œ ë²ˆì—­ ğŸ’¡", "s2s")
                            ],
                            value="llm",
                            label="ë²ˆì—­ ëª¨ë¸",
                            elem_classes="radio-group"
                        )

                        translate_btn = gr.Button(
                            value="ë²ˆì—­ ì‹¤í–‰í•˜ê¸°",
                            size='lg',
                            variant="primary",
                            interactive=True
                        )

                        gr.HTML("<div style='text-align:right'><p style='color:grey;'>ì²˜ìŒ ì‹¤í–‰ ì‹œ ëª¨ë¸ì„ ë‹¤ìš´ë°›ëŠ”ë° ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤.</p><p style='color:orange;'>LLM: 5-10ë°° ë¹ ë¥¸ ì†ë„, ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì²´</p><p style='color:green;'>Seq2Seq: ì•ˆì •ì  ë²ˆì—­, ë‚®ì€ VRAM</p></div>")

                        with gr.Row():
                            status_msg = gr.Textbox(
                                label="í˜„ì¬ ìƒíƒœ",
                                scale=4,
                                value='ë²ˆì—­ ëŒ€ê¸° ì¤‘...'
                            )

                            btn_openfolder = gr.Button(
                                value='ğŸ“‚ ë²ˆì—­ ì™„ë£Œí•œ íŒŒì¼ë“¤ ë³´ê¸°',
                                scale=1,
                                variant="secondary"
                            )
                            btn_openfolder.click(
                                fn=lambda: self.open_folder(),
                                inputs=None,
                                outputs=None
                            )

                        # ë²ˆì—­ ë¡œê·¸ íˆìŠ¤í† ë¦¬
                        gr.Markdown("<h3>ğŸ“œ ë²ˆì—­ íˆìŠ¤í† ë¦¬</h3>")
                        log_display = gr.Textbox(
                            label="ë²ˆì—­ ê¸°ë¡",
                            value="",
                            lines=10,
                            max_lines=15,
                            interactive=False,
                            elem_classes="log-box"
                        )

                        translate_btn.click(
                            fn=self.translateFn,
                            inputs=model_selector,
                            outputs=[status_msg, log_display]
                        )

        app.queue().launch(
            inbrowser=True,
            allowed_paths=["."]
        )

    def finalize_fn(self) -> str:
        sec = self.check_time()
        self.start = None
        return sec

    def get_vllm_model(self):
        """vLLM ëª¨ë¸ ì´ˆê¸°í™”/êµì²´"""
        # models í´ë” ìƒì„±
        models_dir = os.path.join(os.getcwd(), "models")
        os.makedirs(models_dir, exist_ok=True)

        need_reload = (self.llm is None) or (self.loaded_model_name != self.selected_model)

        if need_reload:
            if self.llm is not None and self.loaded_model_name != self.selected_model:
                print(f"vLLM ëª¨ë¸ ë³€ê²½: {self.loaded_model_name} â†’ {self.selected_model}")
                # ê¸°ì¡´ ì—”ì§„ í•´ì œ ë° ìºì‹œ ì •ë¦¬
                self.llm = None
                try:
                    gc.collect()
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                except Exception:
                    pass

            print(f"vLLM ëª¨ë¸ ë¡œë”© ì¤‘: {self.selected_model}")

            self.llm = LLM(
                model=self.selected_model,
                download_dir=models_dir,  # models í´ë”ì— ë‹¤ìš´ë¡œë“œ
                tensor_parallel_size=1,
                gpu_memory_utilization=0.91,
                max_model_len=1024,
                dtype="auto",
                kv_cache_dtype="fp8",
                enforce_eager=True,
                trust_remote_code=True
            )

            # ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„° ì„¤ì • (ë²ˆì—­ í’ˆì§ˆ ìµœì í™”)
            self.sampling_params = SamplingParams(
                temperature=0.3,
                top_p=0.95,
                max_tokens=128,
                repetition_penalty=1.1,
                skip_special_tokens=True,
                stop=["\n", "English:", "Korean:", "---", "###"]
            )

            self.loaded_model_name = self.selected_model
            print("vLLM ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

        return self.llm

    

    def get_seq2seq_model(self):
        """Seq2Seq (NLLB) ëª¨ë¸ ì´ˆê¸°í™”"""
        if self.s2s_model is None:
            print(f"Seq2Seq ëª¨ë¸ ë¡œë”© ì¤‘...")

            # models í´ë” ìƒì„±
            models_dir = os.path.join(os.getcwd(), "models")
            os.makedirs(models_dir, exist_ok=True)

            # ì–¸ì–´ë³„ ëª¨ë¸ ì„ íƒ
            if self.origin_lang == "en":
                model_name = "NHNDQ/nllb-finetuned-en2ko"
                self.src_lang = "eng_Latn"
                self.tgt_lang = "kor_Hang"
            else:
                model_name = "NHNDQ/nllb-finetuned-ko2en"
                self.src_lang = "kor_Hang"
                self.tgt_lang = "eng_Latn"

            print(f"ëª¨ë¸: {model_name}")

            # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
            self.s2s_model = AutoModelForSeq2SeqLM.from_pretrained(
                model_name,
                cache_dir=models_dir
            )
            self.s2s_tokenizer = AutoTokenizer.from_pretrained(
                model_name,
                cache_dir=models_dir,
                src_lang=self.src_lang,
                tgt_lang=self.tgt_lang
            )

            # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPUë¡œ ì´ë™
            if torch.cuda.is_available():
                self.s2s_model = self.s2s_model.cuda()

            print("Seq2Seq ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

        return self.s2s_model

    def translate_text(self, text: str) -> str:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ë²ˆì—­ (ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ ë¡œì§ ì‚¬ìš©)"""
        if not text.strip():
            return ""

        if self.model_type == "llm":
            # LLM: domain_fewshot ì „ëµ (prompt_tuner.py ê²€ì¦ ê²°ê³¼ ì ìš©)
            if self.origin_lang == "en":
                prompt = f"""You are a professional translator.
Preserve tone and nuances.
Output only the Korean translation without quotes or labels.

Examples:
English: "Good morning."
Korean: "ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤."

English: "Thank you very much."
Korean: "ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤."

Now translate this:
English: "{text}"
Korean:"""
            else:
                prompt = f"""You are a professional translator.
Preserve tone and nuances.
Output only the English translation without quotes or labels.

Examples:
Korean: "ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤."
English: "Good morning."

Korean: "ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤."
English: "Thank you very much."

Now translate this:
Korean: "{text}"
English:"""

            # vLLM ì¶”ë¡ 
            outputs = self.llm.generate([prompt], self.sampling_params)
            translated = outputs[0].outputs[0].text.strip()

            # í›„ì²˜ë¦¬: ë¶ˆí•„ìš”í•œ ë”°ì˜´í‘œ ì œê±°
            translated = translated.strip('"').strip("'").strip()

        else:  # s2s
            # Seq2Seq: ì§ì ‘ ëª¨ë¸ ì‚¬ìš©
            inputs = self.s2s_tokenizer(text, return_tensors="pt", padding=True)
            if torch.cuda.is_available():
                inputs = {k: v.cuda() for k, v in inputs.items()}

            outputs = self.s2s_model.generate(**inputs, max_length=self.max_len)
            translated = self.s2s_tokenizer.decode(outputs[0], skip_special_tokens=True)

        return translated

    def translate_batch(self, texts: List[str]) -> List[str]:
        """ë°°ì¹˜ ë²ˆì—­ (ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ ë¡œì§ ì‚¬ìš©)"""
        if not texts:
            return []

        # ë¹ˆ í…ìŠ¤íŠ¸ í•„í„°ë§
        non_empty_indices = [i for i, text in enumerate(texts) if text.strip()]
        non_empty_texts = [texts[i] for i in non_empty_indices]

        if not non_empty_texts:
            return [""] * len(texts)

        if self.model_type == "llm":
            # LLM: domain_fewshot ì „ëµ (prompt_tuner.py ê²€ì¦ ê²°ê³¼ ì ìš©)
            if self.origin_lang == "en":
                prompts = [f"""You are a professional translator.
Preserve tone and nuances.
Output only the Korean translation without quotes or labels.

Examples:
English: "Good morning."
Korean: "ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤."

English: "Thank you very much."
Korean: "ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤."

Now translate this:
English: "{text}"
Korean:""" for text in non_empty_texts]
            else:
                prompts = [f"""You are a professional translator.
Preserve tone and nuances.
Output only the English translation without quotes or labels.

Examples:
Korean: "ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤."
English: "Good morning."

Korean: "ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤."
English: "Thank you very much."

Now translate this:
Korean: "{text}"
English:""" for text in non_empty_texts]

            # vLLM ë°°ì¹˜ ì¶”ë¡ 
            outputs = self.llm.generate(prompts, self.sampling_params)
            translated_non_empty = [
                output.outputs[0].text.strip().strip('"').strip("'").strip()  # í›„ì²˜ë¦¬ ì¶”ê°€
                for output in outputs
            ]

        else:  # s2s
            # Seq2Seq: ë°°ì¹˜ ë²ˆì—­
            inputs = self.s2s_tokenizer(non_empty_texts, return_tensors="pt", padding=True, truncation=True)
            if torch.cuda.is_available():
                inputs = {k: v.cuda() for k, v in inputs.items()}

            outputs = self.s2s_model.generate(**inputs, max_length=self.max_len)
            translated_non_empty = [
                self.s2s_tokenizer.decode(output, skip_special_tokens=True)
                for output in outputs
            ]

        # ê²°ê³¼ ì¬êµ¬ì„± (ë¹ˆ í…ìŠ¤íŠ¸ ìœ„ì¹˜ ë³µì›)
        result = [""] * len(texts)
        for i, translated in zip(non_empty_indices, translated_non_empty):
            result[i] = translated

        return result

    def translateFn(self, model_type: str, progress=gr.Progress()):
        if not self.selected_files:
            current_log = self.get_translation_logs()
            return "ë²ˆì—­í•  íŒŒì¼ì„ ì¶”ê°€í•˜ì„¸ìš”.", current_log

        # ëª¨ë¸ íƒ€ì… ì„¤ì •
        self.model_type = model_type

        self.start = time.time()

        # ëª¨ë¸ë³„ ì´ˆê¸°í™”
        if self.model_type == "llm":
            progress(0, desc="LLM ë²ˆì—­ ëª¨ë¸ì„ ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤...")
            self.get_vllm_model()
        else:
            progress(0, desc="Seq2Seq ë²ˆì—­ ëª¨ë¸ì„ ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤...")
            self.get_seq2seq_model()

        origin_abb = self.origin_lang
        target_abb = "ko" if self.origin_lang == "en" else "en"

        # íŒŒì¼ ê°œìˆ˜ ê¸°ë¡
        file_count = len(self.selected_files)

        for file in progress.tqdm(self.selected_files, desc='íŒŒì¼ë¡œë”©'):
            name, ext = os.path.splitext(file['orig_name'])

            if 'epub' in ext:
                self.translate_epub(file, name, ext, origin_abb, target_abb, progress)

            elif 'srt' in ext:
                self.translate_srt(file, name, ext, origin_abb, target_abb, progress)

            else:  # txt
                self.translate_txt(file, name, ext, origin_abb, target_abb, progress)

        sec = self.finalize_fn()
        model_name = "LLM (iris-7b)" if self.model_type == "llm" else "Seq2Seq (NLLB)"

        # ë²ˆì—­ ë°©í–¥ ë¬¸ìì—´ ìƒì„±
        lang_direction = f"{self.origin_lang_str} â†’ {self.target_lang_str}"

        # ë¡œê·¸ ì¶”ê°€
        updated_log = self.add_translation_log(model_name, sec, file_count, lang_direction)

        # ìƒíƒœ ì´ˆê¸°í™” (ë‹¤ìŒ ë²ˆì—­ì„ ìœ„í•´)
        self.reset_translation_state()

        status_message = f"âœ… ë²ˆì—­ ì™„ë£Œ! ëª¨ë¸: {model_name}, ê±¸ë¦° ì‹œê°„: {sec}"

        return status_message, updated_log

    def translate_txt(self, file, name, ext, origin_abb, target_abb, progress):
        """TXT íŒŒì¼ ë²ˆì—­"""
        output_file_1, output_file_2, book = self.get_file_info(origin_abb, target_abb, name, ext, file)

        book_list = book.read().split(sep='\n')

        for paragraph in progress.tqdm(book_list, desc='ë‹¨ë½'):
            if not paragraph.strip():
                output_file_1.write('\n')
                output_file_2.write('\n')
                continue

            # ë¬¸ì¥ ë¶„ë¦¬
            sentences = nltk.sent_tokenize(paragraph)

            # ë°°ì¹˜ ë²ˆì—­
            translated_sentences = self.translate_batch(sentences)

            # íŒŒì¼ ì‘ì„±
            for orig, trans in zip(sentences, translated_sentences):
                output_file_1.write(f"{trans} ({orig}) ")
                output_file_2.write(f'{trans} ')

            output_file_1.write('\n')
            output_file_2.write('\n')

        output_file_1.close()
        output_file_2.close()
        book.close()

    def translate_srt(self, file, name, ext, origin_abb, target_abb, progress):
        """SRT íŒŒì¼ ë²ˆì—­"""
        output_file_1, output_file_2, book = self.get_file_info(origin_abb, target_abb, name, ext, file)
        srt_list = self.get_srt_list(book.read())

        # ëª¨ë“  ìë§‰ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        texts = [item['text'] for item in srt_list]

        # ë°°ì¹˜ ë²ˆì—­
        translated_texts = self.translate_batch(texts)

        # SRT í˜•ì‹ìœ¼ë¡œ ì‘ì„±
        for item, translated in progress.tqdm(zip(srt_list, translated_texts), desc='ìë§‰', total=len(srt_list)):
            translated = translated.replace('.', '')  # SRTëŠ” ë§ˆì¹¨í‘œ ì œê±°
            output_file_1.write(f"{item['num']}\n{item['time']}\n{translated} ({item['text']})\n\n")
            output_file_2.write(f"{item['num']}\n{item['time']}\n{translated}\n\n")

        output_file_1.close()
        output_file_2.close()
        book.close()

    def translate_epub(self, file, name, ext, origin_abb, target_abb, progress):
        """EPUB íŒŒì¼ ë²ˆì—­"""
        self.zip_extract(self.temp_folder_1, file['path'])
        self.zip_extract(self.temp_folder_2, file['path'])

        file_path = self.get_html_list()

        for html_file in progress.tqdm(file_path, desc='ì±•í„°'):
            html_file_2 = html_file.replace(self.temp_folder_1, self.temp_folder_2)

            input_file_1 = open(html_file, 'r', encoding='utf-8')
            input_file_2 = open(html_file_2, 'r', encoding='utf-8')

            soup_1 = BeautifulSoup(input_file_1.read(), 'html.parser')
            soup_2 = BeautifulSoup(input_file_2.read(), 'html.parser')

            p_tags_1 = soup_1.find_all('p')
            p_tags_2 = soup_2.find_all('p')

            # p íƒœê·¸ê°€ ì—†ìœ¼ë©´ div íƒœê·¸ë¡œ ëŒ€ì²´
            if not p_tags_1:
                p_tags_1 = soup_1.find_all('div')
                p_tags_2 = soup_2.find_all('div')
                for p_tag_1, p_tag_2 in zip(p_tags_1, p_tags_2):
                    if not p_tag_1.find('div'):
                        if p_tag_1.text.strip():
                            p_tag_1.name = 'p'
                            p_tag_2.name = 'p'

                p_tags_1 = soup_1.find_all('p')
                p_tags_2 = soup_2.find_all('p')

            # ê° ë‹¨ë½ ì²˜ë¦¬
            for text_node_1, text_node_2 in progress.tqdm(zip(p_tags_1, p_tags_2), desc='ë‹¨ë½ ìˆ˜', total=len(p_tags_1)):
                if not text_node_1.text.strip():
                    continue

                p_tag_1 = soup_1.new_tag('p')
                p_tag_2 = soup_2.new_tag('p')

                try:
                    if text_node_1.attrs and text_node_1.attrs.get('class'):
                        p_tag_1['class'] = text_node_1.attrs['class']
                        p_tag_2['class'] = text_node_1.attrs['class']
                except:
                    pass

                # ë¬¸ì¥ ë¶„ë¦¬
                sentences = nltk.sent_tokenize(text_node_1.text)

                # ë°°ì¹˜ ë²ˆì—­
                translated_sentences = self.translate_batch(sentences)

                # ë²ˆì—­ ê²°ê³¼ ì¡°í•©
                combined_1 = ' '.join([f"{trans} ({orig})" for orig, trans in zip(sentences, translated_sentences)])
                combined_2 = ' '.join(translated_sentences)

                p_tag_1.string = combined_1
                p_tag_2.string = combined_2

                # ì´ë¯¸ì§€ íƒœê·¸ ìœ ì§€
                img_tag = text_node_1.find('img')
                if img_tag:
                    p_tag_1.append(img_tag)
                    p_tag_2.append(img_tag)

                text_node_1.replace_with(p_tag_1)
                text_node_2.replace_with(p_tag_2)

            input_file_1.close()
            input_file_2.close()

            output_file_1 = open(html_file, 'w', encoding='utf-8')
            output_file_2 = open(html_file_2, 'w', encoding='utf-8')

            output_file_1.write(str(soup_1))
            output_file_2.write(str(soup_2))
            output_file_1.close()
            output_file_2.close()

        # EPUB ì¬íŒ¨í‚¤ì§•
        for loc_folder in [self.temp_folder_1, self.temp_folder_2]:
            self.zip_folder(loc_folder, f'{loc_folder}.epub')

        os.makedirs(self.output_folder, exist_ok=True)

        # ëª¨ë¸ íƒ€ì… ì ‘ë¯¸ì‚¬ ì¶”ê°€
        model_suffix = "llm" if self.model_type == "llm" else "s2s"

        shutil.move(
            f'{self.temp_folder_1}.epub',
            os.path.join(self.output_folder, f"{name}_{target_abb}({origin_abb})_{model_suffix}{ext}")
        )
        shutil.move(
            f'{self.temp_folder_2}.epub',
            os.path.join(self.output_folder, f"{name}_{target_abb}_{model_suffix}{ext}")
        )

        self.remove_folder(self.temp_folder_1)
        self.remove_folder(self.temp_folder_2)

    def get_srt_list(self, srt_file):
        """SRT íŒŒì¼ íŒŒì‹±"""
        srt_list_raw = srt_file.strip().split('\n')
        len_srt = len(srt_list_raw)

        srt_list = []
        recent_num = 0
        for len_idx in range(0, len_srt, 4):
            if len_idx + 2 >= len_srt or not srt_list_raw[len_idx+2].strip():
                continue
            recent_num += 1
            srt_list.append({
                'num': recent_num,
                'time': srt_list_raw[len_idx+1],
                'text': srt_list_raw[len_idx+2].strip(),
            })
        return srt_list

    def change_upload(self, files: List):
        """íŒŒì¼ ì—…ë¡œë“œ ì‹œ ì–¸ì–´ ê°ì§€"""
        try:
            self.selected_files = files
            if not files:
                return self.upload_msg

            aBook = files[0]
            name, ext = os.path.splitext(aBook['path'])

            if '.epub' in ext:
                file = epub.read_epub(aBook['path'])
                lang = file.get_metadata('DC', 'language')
                if lang:
                    check_lang = lang[0][0]
                else:
                    # EPUB ë‚´ìš©ì—ì„œ ì–¸ì–´ ê°ì§€
                    for item in file.get_items():
                        if item.get_type() == ebooklib.ITEM_DOCUMENT:
                            soup = BeautifulSoup(item.get_body_content(), 'html.parser')
                            all_tags = soup.find_all('p')
                            if not all_tags:
                                continue

                            text_tags = [tag.text for tag in all_tags if tag.text.strip()]
                            lang_str = ' '.join(text_tags)
                            check_lang = detect(lang_str[0:500])
                            if 'en' in check_lang or 'ko' in check_lang:
                                break
                            else:
                                return "<p style='text-align:center;color:red;'>í‘œì¤€ ê·œê²©ì„ ë²—ì–´ë‚œ epubì…ë‹ˆë‹¤.</p>"

            elif '.srt' in ext:
                srt_file = self.get_filename(aBook['path'], ext)
                srt_list = self.get_srt_list(srt_file.read())
                srt_texts = ' '.join([srt['text'] for srt in srt_list[:50]])
                check_lang = detect(srt_texts[0:200])
                srt_file.close()
            else:
                book = self.get_filename(aBook['path'], ext)
                check_lang = detect(book.read()[0:200])
                book.close()

            self.origin_lang_str = 'ì˜ì–´' if 'en' in check_lang else "í•œêµ­ì–´"
            self.target_lang_str = 'í•œêµ­ì–´' if 'en' in check_lang else "ì˜ì–´"
            self.origin_lang = "en" if 'en' in check_lang else "ko"
            self.target_lang = "ko" if 'en' in check_lang else "en"

            return f"<p style='text-align:center;'><span style='color:skyblue;font-size:1.5em;'>{self.origin_lang_str}</span><span>ë¥¼ </span> <span style='color:red;font-size:1.5em;'> {self.target_lang_str}</span><span>ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.</span></p>"
        except Exception as err:
            print(f"ì–¸ì–´ ê°ì§€ ì˜¤ë¥˜: {err}")
            return "<p style='text-align:center;color:red;'>ì–´ë–¤ ì–¸ì–´ì¸ì§€ ì•Œì•„ë‚´ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.</p>"

    def get_filename(self, file_name, ext):
        """íŒŒì¼ ì¸ì½”ë”© ê°ì§€ ë° ì—´ê¸°"""
        try:
            if '.srt' in ext:
                encoding = 'utf-8'
            else:
                check_encoding = open(file_name, 'rb')
                result = chardet.detect(check_encoding.read(10000))
                encoding = result['encoding']
                check_encoding.close()
            input_file = open(file_name, 'r', encoding=encoding)
            return input_file
        except Exception as err:
            print(err)
            return None

    def get_file_info(self, origin_abb, target_abb, name, ext, file):
        """ì¶œë ¥ íŒŒì¼ ì •ë³´ ìƒì„±"""
        # ëª¨ë¸ íƒ€ì… ì ‘ë¯¸ì‚¬ ì¶”ê°€
        model_suffix = "llm" if self.model_type == "llm" else "s2s"

        output_file_1 = self.write_filename(f"{name}_{target_abb}({origin_abb})_{model_suffix}{ext}")
        output_file_2 = self.write_filename(f"{name}_{target_abb}_{model_suffix}{ext}")
        book = self.get_filename(file['path'], ext)
        return output_file_1, output_file_2, book

    def write_filename(self, file_name: str):
        """ì¶œë ¥ íŒŒì¼ ìƒì„±"""
        saveDir = self.output_folder
        if not os.path.isdir(saveDir):
            os.makedirs(saveDir)

        file = os.path.join(saveDir, file_name)
        output_file = open(file, 'w', encoding='utf-8')
        return output_file

    def open_folder(self):
        """ì¶œë ¥ í´ë” ì—´ê¸°"""
        saveDir = self.output_folder
        command_to_open = ''

        if not os.path.isdir(saveDir):
            os.makedirs(saveDir)

        if self.platform == 'Windows':
            command_to_open = f"start {saveDir}"
        elif self.platform == 'Darwin':
            command_to_open = f"open {saveDir}"
        elif self.platform == 'Linux':
            command_to_open = f"xdg-open {saveDir}"

        os.system(command_to_open)

    def zip_extract(self, folder_path: PathType, epub_file: PathType):
        """EPUB ì••ì¶• í•´ì œ"""
        try:
            zip_module = zipfile.ZipFile(epub_file, 'r')
            os.makedirs(folder_path, exist_ok=True)
            zip_module.extractall(folder_path)
            zip_module.close()
        except:
            print('ì˜ëª»ëœ epubíŒŒì¼ì…ë‹ˆë‹¤')

    def zip_folder(self, folder_path: PathType, epub_name: PathType):
        """í´ë”ë¥¼ EPUBìœ¼ë¡œ ì••ì¶•"""
        try:
            zip_module = zipfile.ZipFile(epub_name, 'w', zipfile.ZIP_DEFLATED)
            for root, dirs, files in os.walk(folder_path):
                for file in files:
                    file_path = os.path.join(root, file)
                    zip_module.write(file_path, os.path.relpath(file_path, folder_path))
            zip_module.close()
        except Exception as err:
            print('epub íŒŒì¼ì„ ìƒì„±í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
            print(err)

    def get_html_list(self) -> List:
        """EPUB ë‚´ HTML íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        file_paths = []
        for root, _, files in os.walk(self.temp_folder_1):
            for file in files:
                if file.endswith(('xhtml', 'html', 'htm')):
                    file_paths.append(os.path.join(root, file))
        return file_paths

    def check_time(self) -> str:
        """ê²½ê³¼ ì‹œê°„ ê³„ì‚°"""
        end = time.time()
        during = end - self.start
        sec = str(timedelta(seconds=during)).split('.')[0]
        return sec

if __name__ == "__main__":
    capybara = Capybara()
    capybara.main()
