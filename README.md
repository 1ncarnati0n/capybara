# Capybara (ì¹´í”¼ë°”ë¼) ğŸ¦«

ì˜ì–´ â†” í•œêµ­ì–´ ë²ˆì—­ì„ ì§€ì›í•˜ëŠ” ë“€ì–¼ ëª¨ë¸ ì›Œí¬í”Œë¡œìš°ì…ë‹ˆë‹¤. `davidkim205/iris-7b`ë¥¼ vLLMìœ¼ë¡œ êµ¬ë™í•´ ë¹ ë¥¸ ë°°ì¹˜ ë²ˆì—­ì„ ì œê³µí•˜ë©°, VRAMì´ ì œí•œëœ í™˜ê²½ì—ì„œëŠ” Seq2Seq(NLLB) ëª¨ë¸ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë³¸ í”„ë¡œì íŠ¸ëŠ” "[dodari](https://github.com/vEduardovich/dodari)" í”„ë¡œì íŠ¸ì— ì˜ê°ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.

---

## í•µì‹¬ íŠ¹ì§•

- ë‘ ëª¨ë¸ íƒ‘ì¬: ê³ ì† LLM(iris-7b)ê³¼ ê²½ëŸ‰ Seq2Seq(NLLB)
- TXTÂ·EPUBÂ·SRT ì…ë ¥ ì§€ì›, ì›ë¬¸+ë²ˆì—­ë³¸ ë™ì‹œ ì €ì¥

---

## ìš”êµ¬ì‚¬í•­ ìš”ì•½

- **OS**: Linux / WSL2 (Windows) / macOS(ì œí•œì )
- **Python**: 3.11
- **GPU**: CUDA 11.8+ ê¶Œì¥
  - LLM: VRAM 12â€“16GB ê¶Œì¥ (`gpu_memory_utilization=0.91`, `max_model_len=1024` ê¸°ë³¸)
  - Seq2Seq: VRAM 3â€“4GB
- **RAM / Storage**: 16GB RAM, ëª¨ë¸ ìºì‹œ í¬í•¨ 20GB ì´ìƒ ì—¬ìœ 

---

## ë¹ ë¥¸ ì‹œì‘

```bash
# 1. í™˜ê²½ ì¤€ë¹„
conda create -n capybara python=3.11 -y
conda activate capybara

# 2. ì˜ì¡´ì„± ì„¤ì¹˜
cd capybara
pip install -r requirements.txt

# 3. ì‹¤í–‰ (ìë™ ë¸Œë¼ìš°ì €)
bash start.sh
# ë˜ëŠ”
python capybara.py
```

ìµœì´ˆ ì‹¤í–‰ ì‹œ ëª¨ë¸ì´ `capybara/models/`ì— ìºì‹œë©ë‹ˆë‹¤. `nvidia-smi`ë¡œ VRAM ì—¬ìœ ë¥¼ í™•ì¸í•˜ì„¸ìš”.

---

## ì‚¬ìš© ë°©ë²•

1. ë¸Œë¼ìš°ì €(ê¸°ë³¸ í¬íŠ¸ 7860)ì—ì„œ íŒŒì¼ ì—…ë¡œë“œ
2. ì–¸ì–´ ìë™ ê°ì§€ ê²°ê³¼ í™•ì¸ (ì˜â†”í•œ ëª¨ë‘ ì§€ì›)
3. ëª¨ë¸ ì„ íƒ
   - `LLM (iris-7b)` : ë¹ ë¥¸ ë°°ì¹˜ ì²˜ë¦¬, ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„
   - `Seq2Seq (NLLB)` : ë‚®ì€ VRAM, ë³´ìˆ˜ì ì¸ ë²ˆì—­
4. ë²ˆì—­ ì‹¤í–‰ â†’ ì™„ë£Œ í›„ ì¦‰ì‹œ ë‹¤ìŒ íŒŒì¼ ì—…ë¡œë“œ ê°€ëŠ¥

### ì¶œë ¥

`outputs/` í´ë”ì— ë‘ ê°€ì§€ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.
- `íŒŒì¼ëª…_ko(en)_llm.txt` / `_s2s.txt` : ë²ˆì—­ë¬¸ + ì›ë¬¸
- `íŒŒì¼ëª…_ko_llm.txt` / `_s2s.txt`     : ë²ˆì—­ë¬¸ë§Œ

---

## í…ŒìŠ¤íŠ¸ & ì ê²€

í…ŒìŠ¤íŠ¸ êµ¬ì„±ì€ ì´í›„ ê°œí¸ ì˜ˆì •ì´ì§€ë§Œ, í˜„ì¬ëŠ” ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ë¡œ í•µì‹¬ ë™ì‘ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# LLM í’ˆì§ˆ ë° ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„° í™•ì¸
python test_llm.py

# LLM vs Seq2Seq ì†ë„/ì¶œë ¥ ë¹„êµ
python test_models.py

# í”„ë¡¬í”„íŠ¸ ì „ëµ íƒìƒ‰ (ì‹¤í—˜ì )
python test_prompt_tuner.py --file ë¶„ì„ê²°ê³¼/test_prompt.txt --limit 100 --direction auto
```

ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ëŠ” `capybara/ë¶„ì„ê²°ê³¼/`ì— íƒ€ì„ìŠ¤íƒ¬í”„ ë¡œê·¸ë¥¼ ë‚¨ê¹ë‹ˆë‹¤.

---

## ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

- **CUDA OOM**: ë‹¤ë¥¸ GPU ì‘ì—… ì¢…ë£Œ â†’ `gpu_memory_utilization`ì„ 0.88 ì´í•˜ë¡œ ì¡°ì • â†’ í•„ìš” ì‹œ `max_model_len`ì„ 768/512ë¡œ ì¶•ì†Œ
- **vLLM ì„¤ì¹˜ ì‹¤íŒ¨**: Python 3.11Â·CUDA 11.8 ì´ìƒ í™•ì¸ í›„ `pip install --upgrade pip && pip install vllm>=0.8.2`
- **í¬íŠ¸ ì¶©ëŒ**: `capybara.py` ì‹¤í–‰ë¶€ì˜ `server_port` ê°’ì„ 7861 ë“±ìœ¼ë¡œ ë³€ê²½
- **ë²ˆì—­ ì†ë„ ì €í•˜**: `nvidia-smi` ë¡œë“œ í™•ì¸ í›„ ì—¬ìœ  VRAMì—ì„œ `max_num_seqs` ì¦ê°€

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
capybara/
â”œâ”€â”€ capybara.py            # ë©”ì¸ ì•± (Gradio UI + ë²ˆì—­ ë¡œì§)
â”œâ”€â”€ start.sh               # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ test_llm.py            # LLM í’ˆì§ˆ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_models.py         # ë“€ì–¼ ëª¨ë¸ ë¹„êµ
â”œâ”€â”€ test_prompt_tuner.py   # í”„ë¡¬í”„íŠ¸ ì „ëµ ì‹¤í—˜
â”œâ”€â”€ CHANGELOG.md           # ë³€ê²½ ê¸°ë¡
â””â”€â”€ outputs/               # ë²ˆì—­ ê²°ê³¼ (ìë™ ìƒì„±)
```

---

## ë¼ì´ì„ ìŠ¤ & ê¸°ì—¬

- **License**: MIT
- **Contributing**: ì´ìŠˆ/PR í™˜ì˜í•©ë‹ˆë‹¤. ë²„ê·¸ë‚˜ ìš”ì²­ ì‚¬í•­ì€ GitHub ì´ìŠˆë¡œ ë‚¨ê²¨ì£¼ì„¸ìš”.

---

Happy Translating! ğŸ¦«
