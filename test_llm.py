#!/usr/bin/env python3
"""
LLM (iris-7b) ë²ˆì—­ í’ˆì§ˆ í…ŒìŠ¤íŠ¸
ì½˜ì†” ì¶œë ¥ê³¼ ë™ì¼í•œ ë‚´ìš©ì„ capybara/ë¶„ì„ê²°ê³¼ ì— ë¡œê·¸ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""

import os
import sys
import atexit
import time
from datetime import datetime
from vllm import LLM, SamplingParams

# ------------------------------------------------------------
# ê²°ê³¼ ë¡œê·¸: ì½˜ì†” ì¶œë ¥ê³¼ íŒŒì¼ ë™ì‹œ ê¸°ë¡ (ë¶„ì„ê²°ê³¼/)
# ------------------------------------------------------------
def _setup_result_logging(prefix: str = "test_llm") -> str:
    base_dir = os.path.dirname(__file__)
    results_dir = os.path.join(base_dir, "ë¶„ì„ê²°ê³¼")
    os.makedirs(results_dir, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_path = os.path.join(results_dir, f"{prefix}_{ts}.log")

    fh = open(log_path, "w", encoding="utf-8")

    class Tee:
        def __init__(self, *streams):
            self.streams = streams
        def write(self, data):
            for s in self.streams:
                s.write(data)
            for s in self.streams:
                try:
                    s.flush()
                except Exception:
                    pass
        def flush(self):
            for s in self.streams:
                try:
                    s.flush()
                except Exception:
                    pass

    sys.stdout = Tee(sys.stdout, fh)
    sys.stderr = Tee(sys.stderr, fh)
    atexit.register(lambda: fh.close())
    print(f"[LOG] ê²°ê³¼ íŒŒì¼: {log_path}")
    return log_path

_setup_result_logging()

print("=" * 70)
print("LLM (iris-7b) ë²ˆì—­ í’ˆì§ˆ í…ŒìŠ¤íŠ¸")
print("ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ + ìµœì í™”ëœ ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„°")
print("=" * 70)
print()

# vLLM ëª¨ë¸ ë¡œë”©
print("ğŸ”„ vLLM ëª¨ë¸ ë¡œë”© ì¤‘...")
start_load = time.time()

# ê³µìš© ëª¨ë¸ ìºì‹œ ë””ë ‰í† ë¦¬ (í”„ë¡œì íŠ¸ ë‚´ë¶€)
models_dir = os.path.join(os.getcwd(), "models")
os.makedirs(models_dir, exist_ok=True)
print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {models_dir}")

llm = LLM(
    model="davidkim205/iris-7b",
    download_dir=models_dir,
    tensor_parallel_size=1,
    gpu_memory_utilization=0.91,
    max_model_len=1024,
    dtype="auto",
    kv_cache_dtype="fp8",
    enforce_eager=True,
    trust_remote_code=True
)

# ê°œì„ ëœ ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„°
sampling_params = SamplingParams(
    temperature=0.3,           # ê°œì„ : 0.1 â†’ 0.3
    top_p=0.95,                # ê°œì„ : 0.9 â†’ 0.95
    max_tokens=128,            # ê°œì„ : 30 â†’ 128
    repetition_penalty=1.1,    # ìƒˆë¡œ ì¶”ê°€
    skip_special_tokens=True,
    stop=["\n", "English:", "Korean:", "---", "###"]
)

load_time = time.time() - start_load
print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ì†Œìš” ì‹œê°„: {load_time:.2f}ì´ˆ)")
print()

# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
test_cases_en_ko = [
    # ê¸°ë³¸ ì¸ì‚¬
    "Hello, how are you today?",
    "Good morning. Have a nice day!",

    # ê°ì‚¬ í‘œí˜„
    "Thank you very much for your help.",
    "I really appreciate your support.",

    # ê¸´ ë¬¸ì¥ (max_tokens í…ŒìŠ¤íŠ¸)
    "The quick brown fox jumps over the lazy dog, and then runs through the beautiful forest filled with colorful flowers and singing birds.",

    # ë¬¸ë§¥ ì´í•´ (í†¤ ë³´ì¡´)
    "I hope you have a wonderful day ahead of you.",
    "It would be great if we could meet tomorrow.",

    # ë³µì¡í•œ ë¬¸ì¥
    "Machine learning is transforming the way we approach complex problems in various fields.",
    "The company announced that it will launch a new product next month.",

    # ì¼ìƒ ëŒ€í™”
    "What time does the meeting start?",
    "Could you please send me the report by tomorrow?"
]

test_cases_ko_en = [
    # ê¸°ë³¸ ì¸ì‚¬
    "ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?",
    "ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì„¸ìš”!",

    # ê°ì‚¬ í‘œí˜„
    "ë„ì›€ì„ ì£¼ì…”ì„œ ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤.",
    "ë‹¹ì‹ ì˜ ì§€ì›ì— ì§„ì‹¬ìœ¼ë¡œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.",

    # ê¸´ ë¬¸ì¥
    "ë¹ ë¥¸ ê°ˆìƒ‰ ì—¬ìš°ê°€ ê²Œìœ¼ë¥¸ ê°œë¥¼ ë›°ì–´ë„˜ê³ , ê·¸ëŸ° ë‹¤ìŒ ì•„ë¦„ë‹¤ìš´ ê½ƒê³¼ ë…¸ë˜í•˜ëŠ” ìƒˆë“¤ë¡œ ê°€ë“ ì°¬ ìˆ²ì„ ë‹¬ë ¤ê°‘ë‹ˆë‹¤.",

    # ë¬¸ë§¥ ì´í•´
    "ì•ìœ¼ë¡œ ë©‹ì§„ í•˜ë£¨ê°€ ë˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.",
    "ë‚´ì¼ ë§Œë‚  ìˆ˜ ìˆë‹¤ë©´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”.",

    # ë³µì¡í•œ ë¬¸ì¥
    "ê¸°ê³„ í•™ìŠµì€ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ì‹ì„ ë³€í™”ì‹œí‚¤ê³  ìˆìŠµë‹ˆë‹¤.",
    "íšŒì‚¬ëŠ” ë‹¤ìŒ ë‹¬ì— ìƒˆë¡œìš´ ì œí’ˆì„ ì¶œì‹œí•  ê²ƒì´ë¼ê³  ë°œí‘œí–ˆìŠµë‹ˆë‹¤.",

    # ì¼ìƒ ëŒ€í™”
    "íšŒì˜ëŠ” ëª‡ ì‹œì— ì‹œì‘í•˜ë‚˜ìš”?",
    "ë‚´ì¼ê¹Œì§€ ë³´ê³ ì„œë¥¼ ë³´ë‚´ì£¼ì‹œê² ì–´ìš”?"
]

# ===== ì˜ì–´ â†’ í•œêµ­ì–´ ë²ˆì—­ í…ŒìŠ¤íŠ¸ =====
print("=" * 70)
print("í…ŒìŠ¤íŠ¸ 1: ì˜ì–´ â†’ í•œêµ­ì–´ ë²ˆì—­ (ê°œì„ ëœ í”„ë¡¬í”„íŠ¸)")
print("=" * 70)
print()

prompts_en_ko = [f"""You are a professional translator. Translate the following English text to natural Korean. Preserve the tone and nuances.

Examples:
English: "Good morning."
Korean: "ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤."

English: "Thank you very much for your help."
Korean: "ë„ì›€ì„ ì£¼ì…”ì„œ ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤."

English: "I hope you have a wonderful day."
Korean: "ë©‹ì§„ í•˜ë£¨ ë³´ë‚´ì‹œê¸¸ ë°”ëë‹ˆë‹¤."

Now translate this:
English: "{text}"
Korean:""" for text in test_cases_en_ko]

start_translate = time.time()
outputs = llm.generate(prompts_en_ko, sampling_params)
translate_time_en = time.time() - start_translate

for i, (original, output) in enumerate(zip(test_cases_en_ko, outputs), 1):
    translated = output.outputs[0].text.strip().strip('"').strip("'").strip()
    print(f"{i}. EN: {original}")
    print(f"   KO: {translated}")
    print()

print(f"â±ï¸  ë²ˆì—­ ì‹œê°„: {translate_time_en:.2f}ì´ˆ ({len(test_cases_en_ko)}ê°œ ë¬¸ì¥)")
print(f"âš¡ í‰ê·  ì†ë„: {translate_time_en/len(test_cases_en_ko):.2f}ì´ˆ/ë¬¸ì¥")
print()

# ===== í•œêµ­ì–´ â†’ ì˜ì–´ ë²ˆì—­ í…ŒìŠ¤íŠ¸ =====
print("=" * 70)
print("í…ŒìŠ¤íŠ¸ 2: í•œêµ­ì–´ â†’ ì˜ì–´ ë²ˆì—­ (ê°œì„ ëœ í”„ë¡¬í”„íŠ¸)")
print("=" * 70)
print()

prompts_ko_en = [f"""You are a professional translator. Translate the following Korean text to natural English. Preserve the tone and nuances.

Examples:
Korean: "ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤."
English: "Good morning."

Korean: "ë„ì›€ì„ ì£¼ì…”ì„œ ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤."
English: "Thank you very much for your help."

Korean: "ë©‹ì§„ í•˜ë£¨ ë³´ë‚´ì‹œê¸¸ ë°”ëë‹ˆë‹¤."
English: "I hope you have a wonderful day."

Now translate this:
Korean: "{text}"
English:""" for text in test_cases_ko_en]

start_translate = time.time()
outputs = llm.generate(prompts_ko_en, sampling_params)
translate_time_ko = time.time() - start_translate

for i, (original, output) in enumerate(zip(test_cases_ko_en, outputs), 1):
    translated = output.outputs[0].text.strip().strip('"').strip("'").strip()
    print(f"{i}. KO: {original}")
    print(f"   EN: {translated}")
    print()

print(f"â±ï¸  ë²ˆì—­ ì‹œê°„: {translate_time_ko:.2f}ì´ˆ ({len(test_cases_ko_en)}ê°œ ë¬¸ì¥)")
print(f"âš¡ í‰ê·  ì†ë„: {translate_time_ko/len(test_cases_ko_en):.2f}ì´ˆ/ë¬¸ì¥")
print()

# ===== ê°œì„ ì‚¬í•­ ë¹„êµ =====
print("=" * 70)
print("ê°œì„ ì‚¬í•­ ìš”ì•½")
print("=" * 70)
print()
print("ğŸ“Š ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„°:")
print("  - temperature: 0.1 â†’ 0.3 (ë” ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„)")
print("  - top_p: 0.9 â†’ 0.95 (ì–´íœ˜ ë‹¤ì–‘ì„±)")
print("  - max_tokens: 30 â†’ 128 (ê¸´ ë¬¸ì¥ ì™„ì „ ë²ˆì—­)")
print("  - repetition_penalty: ì¶”ê°€ (ë°˜ë³µ ë°©ì§€)")
print()
print("ğŸ“ í”„ë¡¬í”„íŠ¸:")
print("  - Instruction-based ì ‘ê·¼")
print("  - ëª…í™•í•œ ì—­í•  ì •ì˜ (professional translator)")
print("  - í’ˆì§ˆ ì§€ì¹¨ (Preserve tone and nuances)")
print("  - í’ë¶€í•œ ì˜ˆì‹œ")
print()
print("ğŸ¯ í›„ì²˜ë¦¬:")
print("  - ë¶ˆí•„ìš”í•œ ë”°ì˜´í‘œ ì œê±°")
print("  - ê³µë°± ì •ë¦¬")
print()

# ===== ì„±ëŠ¥ í†µê³„ =====
total_time = translate_time_en + translate_time_ko
total_sentences = len(test_cases_en_ko) + len(test_cases_ko_en)

print("=" * 70)
print("ì„±ëŠ¥ í†µê³„")
print("=" * 70)
print()
print(f"ì´ ë²ˆì—­ ì‹œê°„: {total_time:.2f}ì´ˆ")
print(f"ì´ ë¬¸ì¥ ìˆ˜: {total_sentences}ê°œ")
print(f"í‰ê·  ì†ë„: {total_time/total_sentences:.2f}ì´ˆ/ë¬¸ì¥")
print()

print("=" * 70)
print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
print("=" * 70)
print()
print("ë‹¤ìŒ ë‹¨ê³„:")
print("  1. ë²ˆì—­ í’ˆì§ˆ í™•ì¸ (ìì—°ìŠ¤ëŸ¬ì›€, ì •í™•ì„±)")
print("  2. Seq2Seqì™€ ë¹„êµ (python test_models.py)")
print("  3. ì‹¤ì œ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸ (python capybara.py)")
